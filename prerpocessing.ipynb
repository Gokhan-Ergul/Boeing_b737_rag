{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d26359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88f3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_LIMIT = 50\n",
    "FOOTER_LIMIT = 570\n",
    "pdf_path = \"Boeing B737 Manual.pdf\"\n",
    "clipped_pdf_path = \"Boeing_B737_Clipped.pdf\"\n",
    "poppler_bin_path = r\"C:\\poppler-25.12.0\\Library\\bin\"\n",
    "llm_responses_path = \"llm_responses.json\"\n",
    "collection_name = \"my_rag_collection\"\n",
    "qdrant_path = \"./qdrant_db_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd51c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_prep_pdf(input_path, output_path, header_limit, footer_limit):\n",
    "    # 1. Open the file\n",
    "    doc = fitz.open(input_path)\n",
    "    \n",
    "    # 2. Iterate through pages to apply Redactions (Safest method)\n",
    "    for page in doc:\n",
    "        w = page.rect.width\n",
    "        h = page.rect.height\n",
    "        \n",
    "        # Define areas to REMOVE (White box over header/footer)\n",
    "        # Top strip (Header)\n",
    "        header_rect = fitz.Rect(0, 0, w, header_limit)\n",
    "        # Bottom strip (Footer)\n",
    "        footer_rect = fitz.Rect(0, footer_limit, w, h)\n",
    "        \n",
    "        # Add redaction annotations\n",
    "        page.add_redact_annot(header_rect, fill=(1, 1, 1)) \n",
    "        page.add_redact_annot(footer_rect, fill=(1, 1, 1))\n",
    "        \n",
    "        # 3. Apply the redactions\n",
    "        # images=0 prevents it from trying to re-compress images (saves time/errors)\n",
    "        # graphics=0 prevents it from messing with complex vector graphics (avoids P1 error)\n",
    "        page.apply_redactions(images=0, graphics=0, text=1)\n",
    "\n",
    "    # 4. Save with \"clean=True\" and \"garbage=4\"\n",
    "    # garbage=4: Remove unused objects (cleans the corruption)\n",
    "    # clean=True: Re-writes the syntax to fix \"wrong pointing objects\"\n",
    "    doc.save(output_path, garbage=4, clean=True)\n",
    "    doc.close()\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5a58a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boeing_B737_Clipped.pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_prep_pdf(pdf_path, clipped_pdf_path, HEADER_LIMIT, FOOTER_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30a03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if \"tables_images_locations_saved.pkl\" not in os.listdir():   \n",
    "    tables_and_images = camelot.read_pdf(clipped_pdf_path, flavor=\"lattice\", pages=\"all\")\n",
    "else:\n",
    "    with open(\"tables_images_locations_saved.pkl\", \"rb\") as f:\n",
    "        tables_and_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa391d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 0 found on Page: 6\n",
      "Table 1 found on Page: 7\n",
      "Table 2 found on Page: 33\n",
      "Table 3 found on Page: 39\n",
      "Table 4 found on Page: 40\n",
      "Table 5 found on Page: 41\n",
      "Table 6 found on Page: 42\n",
      "Table 7 found on Page: 43\n",
      "Table 8 found on Page: 45\n",
      "Table 9 found on Page: 46\n",
      "Table 10 found on Page: 47\n",
      "Table 11 found on Page: 51\n",
      "Table 12 found on Page: 52\n",
      "Table 13 found on Page: 53\n",
      "Table 14 found on Page: 54\n",
      "Table 15 found on Page: 55\n",
      "Table 16 found on Page: 56\n",
      "Table 17 found on Page: 74\n",
      "Table 18 found on Page: 81\n",
      "Table 19 found on Page: 81\n",
      "Table 20 found on Page: 82\n",
      "Table 21 found on Page: 82\n",
      "Table 22 found on Page: 83\n",
      "Table 23 found on Page: 83\n",
      "Table 24 found on Page: 84\n",
      "Table 25 found on Page: 84\n",
      "Table 26 found on Page: 85\n",
      "Table 27 found on Page: 85\n",
      "Table 28 found on Page: 86\n",
      "Table 29 found on Page: 86\n",
      "Table 30 found on Page: 87\n",
      "Table 31 found on Page: 87\n",
      "Table 32 found on Page: 87\n",
      "Table 33 found on Page: 88\n",
      "Table 34 found on Page: 89\n",
      "Table 35 found on Page: 89\n",
      "Table 36 found on Page: 89\n",
      "Table 37 found on Page: 90\n",
      "Table 38 found on Page: 91\n",
      "Table 39 found on Page: 91\n",
      "Table 40 found on Page: 92\n",
      "Table 41 found on Page: 92\n",
      "Table 42 found on Page: 93\n",
      "Table 43 found on Page: 93\n",
      "Table 44 found on Page: 93\n",
      "Table 45 found on Page: 94\n",
      "Table 46 found on Page: 94\n",
      "Table 47 found on Page: 95\n",
      "Table 48 found on Page: 95\n",
      "Table 49 found on Page: 96\n",
      "Table 50 found on Page: 96\n",
      "Table 51 found on Page: 97\n",
      "Table 52 found on Page: 97\n",
      "Table 53 found on Page: 99\n",
      "Table 54 found on Page: 99\n",
      "Table 55 found on Page: 100\n",
      "Table 56 found on Page: 101\n",
      "Table 57 found on Page: 101\n",
      "Table 58 found on Page: 101\n",
      "Table 59 found on Page: 102\n",
      "Table 60 found on Page: 103\n",
      "Table 61 found on Page: 108\n",
      "Table 62 found on Page: 108\n",
      "Table 63 found on Page: 109\n",
      "Table 64 found on Page: 109\n",
      "Table 65 found on Page: 110\n",
      "Table 66 found on Page: 110\n",
      "Table 67 found on Page: 111\n",
      "Table 68 found on Page: 113\n",
      "Table 69 found on Page: 114\n",
      "Table 70 found on Page: 115\n",
      "Table 71 found on Page: 115\n",
      "Table 72 found on Page: 116\n",
      "Table 73 found on Page: 117\n",
      "Table 74 found on Page: 118\n",
      "Table 75 found on Page: 118\n",
      "Table 76 found on Page: 119\n",
      "Table 77 found on Page: 119\n",
      "Table 78 found on Page: 119\n",
      "Table 79 found on Page: 120\n",
      "Table 80 found on Page: 120\n",
      "Table 81 found on Page: 120\n",
      "Table 82 found on Page: 121\n",
      "Table 83 found on Page: 121\n",
      "Table 84 found on Page: 121\n",
      "Table 85 found on Page: 121\n",
      "Table 86 found on Page: 122\n",
      "Table 87 found on Page: 122\n",
      "Table 88 found on Page: 122\n",
      "Table 89 found on Page: 122\n",
      "Table 90 found on Page: 123\n",
      "Table 91 found on Page: 123\n",
      "Table 92 found on Page: 124\n",
      "Table 93 found on Page: 125\n",
      "Table 94 found on Page: 126\n",
      "Table 95 found on Page: 126\n",
      "Table 96 found on Page: 128\n",
      "Table 97 found on Page: 129\n",
      "Table 98 found on Page: 132\n",
      "Table 99 found on Page: 133\n",
      "Table 100 found on Page: 136\n",
      "Table 101 found on Page: 137\n",
      "Table 102 found on Page: 138\n",
      "Table 103 found on Page: 138\n",
      "Table 104 found on Page: 139\n",
      "Table 105 found on Page: 139\n",
      "Table 106 found on Page: 140\n",
      "Table 107 found on Page: 142\n",
      "Table 108 found on Page: 143\n",
      "Table 109 found on Page: 144\n",
      "Table 110 found on Page: 145\n",
      "Table 111 found on Page: 146\n"
     ]
    }
   ],
   "source": [
    "for i, table in enumerate(tables_and_images):\n",
    "    print(f\"Table {i} found on Page: {table.page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9886c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_page_list = [table.page for table in tables_and_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6fb908",
   "metadata": {},
   "source": [
    "# 1.Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c220953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gökhan ergül\\Desktop\\project\\RAG\\boeing_with_rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a01160",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert Aviation Technical Documentation Specialist.\n",
    "Your input will be images from a Boeing B737 manual (tables, text, or diagrams).\n",
    "Your output will be used to populate a Vector Database for a RAG system.\n",
    "Your goal is to extract information in a way that answers \"Where is X?\", \"How does X work?\", or \"What is the procedure for X?\".\n",
    "\n",
    "Strictly follow these rules:\n",
    "\n",
    "### 1. GENERAL TEXT INTEGRITY (Top Priority)\n",
    "- **Introductory Text:** Extract any introductory text blocks\n",
    "- **verbatim** (word-for-word). Do not paraphrase or summarize these sections.\n",
    "- **Labels:** Use the exact terminology found in the image labels.\n",
    "\n",
    "### 2. FOR TABLES\n",
    "- **Compact Format:** Use standard `|---|` syntax. No pretty-printing.\n",
    "- **Consistent Column Count:** Markdown does not support merged cells (colspan). \n",
    "  - **Rule:** You MUST ensure that **every row** in the table (including headers) has the **same number of columns**.\n",
    "  - **Handling Merged Headers:** If a header spans multiple columns (e.g., \"LIMIT WEIGHT\"), repeat it in empty cells OR flatten the header structure so it aligns with the data columns below.\n",
    "  - **Example:** If the data has 6 columns, the header row must also have 6 columns (using empty cells `| |` if necessary to maintain alignment).\n",
    "- **Line Breaks:** Use `<br>` for line breaks inside cells.\n",
    "- **Content:** Do not summarize.\n",
    "\n",
    "### 3. FOR FLOWCHARTS & PROCESS DIAGRAMS\n",
    "-Identify specific components using standard aviation acronyms (e.g., CDU, MCP, EFIS, Throttle Quadrant) whenever visually recognizable.\n",
    "- **Follow the Numbers:** If the diagram contains numbered steps (e.g., [1], [2], [3]), **strictly follow that numerical sequence** in your description, regardless of standard operating procedures. Describe step [1] first, then [2], etc.\n",
    "- **Describe Sequence:** Use \"First,\" \"Then,\" \"Next.\"\n",
    "- **Example:** \"Step [1]: The scan begins at the side panels... Step [2]: The flow moves to the overhead panel...\"\n",
    "\n",
    "### 4. FOR SCHEMATICS & LOCATION DIAGRAMS\n",
    "- **Do not** use passive visual descriptions like \"There is a line pointing to the wing.\"\n",
    "- **Instead, interpret the visual relation** into definitive technical statements.\n",
    "- Map labels to their physical location on the aircraft (Forward, Aft, Fuselage, Wing, Ceiling, Floor).\n",
    "- **Combine labels with their descriptive text.** If a label has sub-text, merge it into a coherent sentence.\n",
    "- **Example:** \"Integral Slide Lighting is installed at the forward and aft service doors to illuminate the deployment area.\"\n",
    "\n",
    "### 5. OUTPUT FORMAT\n",
    "- Structure your response into two distinct sections:\n",
    "  **[Context Text]**: The verbatim introductory text found on the page.\n",
    "  **[Visual Analysis]**: The structured description of the diagram, table, or schematic.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970522b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model  = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    system_instruction=system_instruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "104694d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "def extract_data_from_images(image_page_list,input_path, image_model, llm_responses_path):\n",
    "    import json\n",
    "    extracted_data = []\n",
    "    failed_pages = []\n",
    "\n",
    "    if os.path.exists(llm_responses_path):\n",
    "        try:\n",
    "            with open(llm_responses_path, \"r\", ) as f:\n",
    "                extracted_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"warning: '{llm_responses_path}' file is empty or broken new file is starting.\")\n",
    "            extracted_data = []\n",
    "\n",
    "\n",
    "    processed_pages = {item['page'] for item in extracted_data}\n",
    "\n",
    "    for page_num in tqdm(image_page_list,desc=\"Processing Pages\"):\n",
    "\n",
    "        if page_num in processed_pages:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            images = convert_from_path(input_path, first_page=page_num, last_page=page_num, poppler_path=poppler_bin_path)\n",
    "            image = images[0]\n",
    "\n",
    "            response = image_model.generate_content(\n",
    "                [\"Analyze this page based on the system instructions.\", image])\n",
    "            \n",
    "            if response.candidates[0].finish_reason == 4:\n",
    "                print(f\"Warning: Page {page_num} was blocked due to copyright (Recitation).\")\n",
    "                failed_pages.append(page_num)\n",
    "                continue\n",
    "\n",
    "\n",
    "            page_content = response.text\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"page\": page_num,\n",
    "                \"content\": page_content\n",
    "            })\n",
    "            processed_pages.add(page_num)\n",
    "\n",
    "            # Save after each extraction to avoid data loss\n",
    "            with open(llm_responses_path, \"w\") as f:\n",
    "                json.dump(extracted_data, f, indent=4)\n",
    "\n",
    "\n",
    "        except ResourceExhausted:\n",
    "            print(f\"Quota exceeded! Waiting 60 seconds... (Page {page_num})\")\n",
    "            time.sleep(60)\n",
    "            failed_pages.append(page_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {page_num}: {e}\")\n",
    "    print(f\"Extraction complete. Successfully processed {len(processed_pages)} pages.\")\n",
    "    print(f\"Failed pages: {failed_pages}\")\n",
    "    print(f\"failed pages number: {len(failed_pages)}\")\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a7cb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pages: 100%|██████████| 112/112 [00:10<00:00, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Page 103 was blocked due to copyright (Recitation).\n",
      "Extraction complete. Successfully processed 71 pages.\n",
      "Failed pages: [103]\n",
      "failed pages number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_from_images = extract_data_from_images(image_page_list, clipped_pdf_path, image_model, llm_responses_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e8fc8",
   "metadata": {},
   "source": [
    "# 2. Chunking (Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072fe27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_chunks_per_page(data_from_images, source_name):\n",
    "    documents = []\n",
    "    token_count_list = []\n",
    "    encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "    manual_split_points = {\n",
    "        82: \"The following table presents Field Limit Weight (1000 KG) and Climb Limit Weight (1000 KG) for 1000 FT Pressure Altitude.\",\n",
    "        83: \"3000 FT Pressure Altitude\", # Bu başlık sayfanın ortasında geçiyor\n",
    "        85: \"### Table: 1000 FT Pressure Altitude\",\n",
    "        86: \"**Table 2: 3000 FT Pressure Altitude**\"\n",
    "    }\n",
    "\n",
    "    for item in data_from_images:\n",
    "        page_num = item['page']\n",
    "        content = item['content']\n",
    "        \n",
    "        if not content or len(content.strip()) < 10:\n",
    "            print(f\"Skipping page {page_num} due to insufficient content.\")\n",
    "            continue\n",
    "\n",
    "        token_count = len(encoder.encode(content))\n",
    "        token_count_list.append(token_count)\n",
    "\n",
    "        if page_num in manual_split_points and token_count > 2000:\n",
    "            separator = manual_split_points[page_num]\n",
    "            \n",
    "            parts = content.split(separator, 1) \n",
    "            \n",
    "            if len(parts) == 2:\n",
    "                print(f\"Page {page_num} manually split into 2 parts (Tokens: {token_count}).\")\n",
    "                \n",
    "                meta1 = {\n",
    "                    \"source\": source_name, \"page\": page_num, \n",
    "                    \"chunk_type\": \"image_extracted_part\", \"part\": 1, \"total_parts\": 2\n",
    "                }\n",
    "                documents.append(Document(page_content=parts[0].strip(), metadata=meta1))\n",
    "                \n",
    "                part2_content = separator + \"\\n\" + parts[1].strip()\n",
    "                meta2 = {\n",
    "                    \"source\": source_name, \"page\": page_num, \n",
    "                    \"chunk_type\": \"image_extracted_part\", \"part\": 2, \"total_parts\": 2\n",
    "                }\n",
    "                documents.append(Document(page_content=part2_content, metadata=meta2))\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"WARNING: Could not find separator for Page {page_num}. Processing as single chunk.\")\n",
    "\n",
    "        if token_count > 2000 and page_num not in manual_split_points:\n",
    "             print(f\"Warning: Page {page_num} has {token_count} tokens but no manual split defined. Adding as is.\")\n",
    "\n",
    "        metadata = {\n",
    "            \"source\": source_name,\n",
    "            \"page\": page_num,\n",
    "            \"chunk_type\": \"image_extracted\"\n",
    "        }\n",
    "        doc = Document(page_content=content, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents, token_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc1f9178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 82 manually split into 2 parts (Tokens: 2410).\n",
      "Page 83 manually split into 2 parts (Tokens: 3331).\n",
      "Page 85 manually split into 2 parts (Tokens: 4126).\n",
      "Page 86 manually split into 2 parts (Tokens: 2592).\n"
     ]
    }
   ],
   "source": [
    "chunked_response, token_count_list = create_chunks_per_page(data_from_images, \"llm_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e22460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fbf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_page_list = list(set(image_page_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b769ecaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4126, 3331, 2592, 2410, 1903, 1707, 1670, 1605, 1603, 1530, 1399,\n",
       "       1304, 1150, 1033,  942,  902,  796,  685,  653,  588])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shoerted_token_count = np.sort(token_count_list)[::-1]\n",
    "\n",
    "shoerted_token_count[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de5a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,      \n",
    "    chunk_overlap=150, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], \n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "703ae9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks_for_text_only(image_page_list,source_name,clipped_pdf_path, text_splitter):\n",
    "    doc  = fitz.open(clipped_pdf_path)\n",
    "    text_chunks = []\n",
    "    for item in doc:\n",
    "        if item.number + 1 not in image_page_list:\n",
    "            text_content = item.get_text()\n",
    "            page = item.number + 1\n",
    "\n",
    "            metadata = {\n",
    "                \"source\": source_name,\n",
    "                \"page\": page,\n",
    "                \"chunk_type\": \"text_only\"\n",
    "            }\n",
    "            if len(text_content.strip()) < 20:\n",
    "                continue\n",
    "            \n",
    "            chunks = text_splitter.create_documents([text_content], metadatas=[metadata])\n",
    "            text_chunks.extend(chunks)\n",
    "\n",
    "    return text_chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df247d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text_only = create_chunks_for_text_only(image_page_list, \"Boeing_B737_Clipped.pdf\", clipped_pdf_path, text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a4e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = chunked_response + chunked_text_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96548933",
   "metadata": {},
   "source": [
    "# 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eea77958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gökhan ergül\\AppData\\Local\\Temp\\ipykernel_25484\\2460608055.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset is loading... to qdrant database 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gökhan ergül\\AppData\\Local\\Temp\\ipykernel_25484\\2460608055.py:32: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPERATION SUCCESSFUL! The database was set up appropriately for the size of the model.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "#from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "#embedding_model = GoogleGenerativeAIEmbeddings( #i dont have that much money the free tier not enough\n",
    " #   model=\"gemini-embedding-001\"\n",
    "#)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "client = QdrantClient(path=qdrant_path)\n",
    "\n",
    "\n",
    "print(f\"the dataset is loading... to qdrant database {len(all_chunks)}\")\n",
    "chunk_ids = []\n",
    "for chunk in all_chunks:\n",
    "    content = chunk.page_content\n",
    "    id_hash = hashlib.md5(content.encode('utf-8')).hexdigest()\n",
    "    chunk_ids.append(id_hash)\n",
    "\n",
    "\n",
    "try:\n",
    "    dummy_vec = embedding_model.embed_query(\"test\")\n",
    "    vec_size = len(dummy_vec)\n",
    "\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vec_size, distance=Distance.COSINE),\n",
    "    )\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embedding_model,\n",
    "    )\n",
    "    vector_store.add_documents(\n",
    "        documents=all_chunks,\n",
    "        ids=chunk_ids,\n",
    "        batch_size=50\n",
    "    )\n",
    "    \n",
    "    print(\"OPERATION SUCCESSFUL! The database was set up appropriately for the size of the model.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059d190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
